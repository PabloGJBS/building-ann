{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit5aff65cb5d064dc4bf8e53621272c904",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow==1.13.1 (from -r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy==1.16.2 (from -r requirements.txt (line 2))\n",
      "  Using cached https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pandas==0.24.2 (from -r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting matplotlib==3.0.3 (from -r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting Keras==2.2.4 (from -r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
      "Collecting sklearn==0.0 (from -r requirements.txt (line 6))\n",
      "Collecting six>=1.10.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/fe/fd/247ef25f5ec5f9acecfbc98ca3c6aaf66716cf52509aca9a93583d410493/protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "Collecting wheel>=0.26 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/00/3df031b3ecd5444d572141321537080b40c1c25e1caa3d86cdd12e5e919c/wheel-0.35.1-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/58/0aa6fb779dc69cfc811df3398fcbeaeefbf18561b6e36b185df0782781cc/absl_py-0.11.0-py3-none-any.whl\n",
      "Collecting pytz>=2011k (from pandas==0.24.2->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.5.0 (from pandas==0.24.2->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/1b/cbd8ae738719b5f41592a12057ef5442e2ed5f5cb5451f8fc7e9f8875a1a/kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting cycler>=0.10 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting h5py (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/70/7a/e53e500335afb6b1aade11227cdf107fca54106a1dca5c9d13242a043f3b/h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting scipy>=0.14 (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pyyaml (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "Collecting scikit-learn (from sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/ef/24a91ca96efa0d7802dffb83ccc7a3c677027bea19ec3c9ee80be740408e/Markdown-3.3.3-py3-none-any.whl\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
      "Collecting cached-property; python_version < \"3.8\" (from h5py->Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/6d/f4bb28424bc677bce1210bc19f69a43efe823e294325606ead595211f93e/importlib_metadata-2.0.0-py2.py3-none-any.whl\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/41/ad/6a4f1a124b325618a7fb758b885b68ff7b058eec47d9220a12ab38d90b1f/zipp-3.4.0-py3-none-any.whl\n",
      "Installing collected packages: six, astor, protobuf, werkzeug, absl-py, zipp, importlib-metadata, markdown, grpcio, numpy, wheel, tensorboard, keras-preprocessing, termcolor, cached-property, h5py, keras-applications, gast, mock, tensorflow-estimator, tensorflow, pytz, python-dateutil, pandas, pyparsing, kiwisolver, cycler, matplotlib, scipy, pyyaml, Keras, joblib, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed Keras-2.2.4 absl-py-0.11.0 astor-0.8.1 cached-property-1.5.2 cycler-0.10.0 gast-0.4.0 grpcio-1.33.2 h5py-3.1.0 importlib-metadata-2.0.0 joblib-0.17.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 kiwisolver-1.3.1 markdown-3.3.3 matplotlib-3.0.3 mock-4.0.2 numpy-1.16.2 pandas-0.24.2 protobuf-3.14.0 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 pyyaml-5.3.1 scikit-learn-0.23.2 scipy-1.5.4 six-1.15.0 sklearn-0.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 threadpoolctl-2.1.0 werkzeug-1.0.1 wheel-0.35.1 zipp-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Neural Network\n",
    "\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# pip install tensorflow\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras\n",
    "\n",
    "# Part 1 - Data Preprocessing\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n [608 'Spain' 0 ... 0 1 112542.58]\n [502 'France' 0 ... 1 0 113931.57]\n ...\n [709 'France' 0 ... 0 1 42085.58]\n [772 'Germany' 1 ... 1 0 92888.52]\n [792 'France' 0 ... 1 0 38190.78]]\n[[1.0 0.0 0.0 ... 1 1 101348.88]\n [0.0 0.0 1.0 ... 0 1 112542.58]\n [1.0 0.0 0.0 ... 1 0 113931.57]\n ...\n [1.0 0.0 0.0 ... 0 1 42085.58]\n [0.0 1.0 0.0 ... 1 0 92888.52]\n [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding the \"Gender\" column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])\n",
    "print(X)\n",
    "# One Hot Encoding the \"Geography\" column\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8000, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/paulo/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/paulo/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 4s 530us/step - loss: 0.4934 - acc: 0.7955\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 3s 353us/step - loss: 0.4259 - acc: 0.8009\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 3s 347us/step - loss: 0.4173 - acc: 0.8262\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2s 250us/step - loss: 0.4107 - acc: 0.8294\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.4064 - acc: 0.8325\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.4038 - acc: 0.8339\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 2s 301us/step - loss: 0.4024 - acc: 0.8336\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.4007 - acc: 0.8359\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 2s 266us/step - loss: 0.3998 - acc: 0.8342\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 3s 317us/step - loss: 0.3995 - acc: 0.8342\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdc554de940>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "# classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making predictions and evaluating the model\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting a single new observation\n",
    "\"\"\"Predict if the customer with the following informations will leave the bank:\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Gender: Male\n",
    "Age: 40\n",
    "Tenure: 3\n",
    "Balance: 60000\n",
    "Number of Products: 2\n",
    "Has Credit Card: Yes\n",
    "Is Active Member: Yes\n",
    "Estimated Salary: 50000\n",
    "Exited: Yes\"\"\"\n",
    "new_prediction = classifier.predict(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000, 1]])))\n",
    "new_prediction = (new_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1541   54]\n [ 263  142]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4 - Evaluating, Improving and Tuning the ANN\n",
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras.layers import Dropout\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 10)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.83125    0.81499999 0.82499999 0.8175     0.81625    0.8275\n 0.83125    0.81125    0.82249999 0.79499999]\n0.8192499954998492\n0.010401322329163704\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)\n",
    "print(mean)\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving the ANN\n",
    "# Dropout Regularization to reduce overfitting if needed\n",
    "# Tuning the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size': [5, 10],\n",
    "              'epochs': [5, 10],\n",
    "              'optimizer': ['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           scoring = 'accuracy',\n",
    "                           param_grid = parameters,\n",
    "                           cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".7971\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 426us/step - loss: 0.4272 - acc: 0.8179\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 341us/step - loss: 0.4247 - acc: 0.8217\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5024 - acc: 0.7961\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 4s 513us/step - loss: 0.4351 - acc: 0.7967\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 348us/step - loss: 0.4350 - acc: 0.7967\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 346us/step - loss: 0.4306 - acc: 0.7967\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 340us/step - loss: 0.4306 - acc: 0.7967\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 4s 526us/step - loss: 0.4276 - acc: 0.7967\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 417us/step - loss: 0.4273 - acc: 0.7997\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 407us/step - loss: 0.4244 - acc: 0.8186\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 4s 539us/step - loss: 0.4284 - acc: 0.8229\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 5s 688us/step - loss: 0.4252 - acc: 0.8283\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.6206 - acc: 0.7942\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 470us/step - loss: 0.5272 - acc: 0.8014\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 355us/step - loss: 0.4633 - acc: 0.8250\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 412us/step - loss: 0.4299 - acc: 0.8333\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 4s 509us/step - loss: 0.4153 - acc: 0.8347\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 468us/step - loss: 0.4052 - acc: 0.8337\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 363us/step - loss: 0.4049 - acc: 0.8346\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 4s 488us/step - loss: 0.3972 - acc: 0.8361\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.3963 - acc: 0.8351\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 350us/step - loss: 0.3985 - acc: 0.8353\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.4905 - acc: 0.7974\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 348us/step - loss: 0.4353 - acc: 0.7975\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 337us/step - loss: 0.4327 - acc: 0.7975\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 334us/step - loss: 0.4277 - acc: 0.7975\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 447us/step - loss: 0.4247 - acc: 0.7975\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 341us/step - loss: 0.4238 - acc: 0.8071\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 329us/step - loss: 0.4237 - acc: 0.8228\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 305us/step - loss: 0.4242 - acc: 0.8226\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 463us/step - loss: 0.4260 - acc: 0.8244\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 324us/step - loss: 0.4212 - acc: 0.8271\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.4982 - acc: 0.7933\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 307us/step - loss: 0.4283 - acc: 0.8151\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 4s 493us/step - loss: 0.4219 - acc: 0.8183\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 354us/step - loss: 0.4174 - acc: 0.8182\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 325us/step - loss: 0.4121 - acc: 0.8206\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 445us/step - loss: 0.4151 - acc: 0.8189\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 396us/step - loss: 0.4083 - acc: 0.8199\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 326us/step - loss: 0.4107 - acc: 0.8201\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 349us/step - loss: 0.4102 - acc: 0.8168\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 479us/step - loss: 0.4062 - acc: 0.8203\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.4991 - acc: 0.7935\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 6s 796us/step - loss: 0.4371 - acc: 0.7944\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 413us/step - loss: 0.4344 - acc: 0.7944\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 339us/step - loss: 0.4307 - acc: 0.7944\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 365us/step - loss: 0.4302 - acc: 0.7944\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 4s 526us/step - loss: 0.4248 - acc: 0.8014\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 378us/step - loss: 0.4286 - acc: 0.8247\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 480us/step - loss: 0.4289 - acc: 0.8218\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 4s 506us/step - loss: 0.4279 - acc: 0.8262\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 396us/step - loss: 0.4270 - acc: 0.8269\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5011 - acc: 0.7968\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 4s 539us/step - loss: 0.4328 - acc: 0.7969\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 4s 598us/step - loss: 0.4316 - acc: 0.7969\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 440us/step - loss: 0.4265 - acc: 0.7969\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 5s 636us/step - loss: 0.4206 - acc: 0.7969\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 464us/step - loss: 0.4200 - acc: 0.7969\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 414us/step - loss: 0.4139 - acc: 0.8156\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 481us/step - loss: 0.4152 - acc: 0.8167\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 364us/step - loss: 0.4107 - acc: 0.8201\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 365us/step - loss: 0.4095 - acc: 0.8214\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5005 - acc: 0.7954\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 6s 814us/step - loss: 0.4373 - acc: 0.7962\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 4s 508us/step - loss: 0.4351 - acc: 0.7962\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 447us/step - loss: 0.4324 - acc: 0.7962\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 343us/step - loss: 0.4286 - acc: 0.7962\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 479us/step - loss: 0.4274 - acc: 0.7962\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 378us/step - loss: 0.4293 - acc: 0.7962\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.4270 - acc: 0.7962\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 463us/step - loss: 0.4247 - acc: 0.8158\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 391us/step - loss: 0.4282 - acc: 0.8231\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5276 - acc: 0.7949\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 351us/step - loss: 0.4449 - acc: 0.7957\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 4s 507us/step - loss: 0.4374 - acc: 0.7957\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 405us/step - loss: 0.4350 - acc: 0.7957\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 429us/step - loss: 0.4317 - acc: 0.7957\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 4s 506us/step - loss: 0.4337 - acc: 0.7957\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 375us/step - loss: 0.4312 - acc: 0.7957\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 351us/step - loss: 0.4330 - acc: 0.7957\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 4s 514us/step - loss: 0.4338 - acc: 0.7957\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 383us/step - loss: 0.4303 - acc: 0.7957\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.4922 - acc: 0.7960\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 414us/step - loss: 0.4373 - acc: 0.7961\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 481us/step - loss: 0.4328 - acc: 0.7961\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 364us/step - loss: 0.4279 - acc: 0.7961\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 368us/step - loss: 0.4212 - acc: 0.8043\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 4s 549us/step - loss: 0.4172 - acc: 0.8194\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.4156 - acc: 0.8229\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 401us/step - loss: 0.4154 - acc: 0.8219\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 4s 508us/step - loss: 0.4064 - acc: 0.8229\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 384us/step - loss: 0.4082 - acc: 0.8233\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5097 - acc: 0.7967\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 4s 505us/step - loss: 0.4397 - acc: 0.7971\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 417us/step - loss: 0.4352 - acc: 0.7971\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 391us/step - loss: 0.4328 - acc: 0.7971\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 4s 488us/step - loss: 0.4311 - acc: 0.7971\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 486us/step - loss: 0.4316 - acc: 0.7971\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 423us/step - loss: 0.4293 - acc: 0.8147\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 467us/step - loss: 0.4302 - acc: 0.8204\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 469us/step - loss: 0.4262 - acc: 0.8236\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 376us/step - loss: 0.4282 - acc: 0.8268\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5112 - acc: 0.7969\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 475us/step - loss: 0.4400 - acc: 0.7967\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 434us/step - loss: 0.4353 - acc: 0.7967\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 4s 607us/step - loss: 0.4312 - acc: 0.7967\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 432us/step - loss: 0.4311 - acc: 0.7967\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 399us/step - loss: 0.4293 - acc: 0.7967\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 4s 494us/step - loss: 0.4293 - acc: 0.8033\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 421us/step - loss: 0.4259 - acc: 0.8206\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.4285 - acc: 0.8276\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 369us/step - loss: 0.4234 - acc: 0.8272\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 11s 1ms/step - loss: 0.5066 - acc: 0.7954\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 375us/step - loss: 0.4416 - acc: 0.7956\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 352us/step - loss: 0.4363 - acc: 0.7956\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 4s 538us/step - loss: 0.4280 - acc: 0.7956\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 291us/step - loss: 0.4306 - acc: 0.7967\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 249us/step - loss: 0.4295 - acc: 0.8192\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 222us/step - loss: 0.4263 - acc: 0.8208\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 451us/step - loss: 0.4241 - acc: 0.8251\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.4253 - acc: 0.8246\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 412us/step - loss: 0.4277 - acc: 0.8217\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 11s 1ms/step - loss: 0.5066 - acc: 0.7972\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 429us/step - loss: 0.4380 - acc: 0.7975\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 375us/step - loss: 0.4341 - acc: 0.7975\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 4s 507us/step - loss: 0.4310 - acc: 0.7975\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 433us/step - loss: 0.4277 - acc: 0.7975\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 398us/step - loss: 0.4271 - acc: 0.7975\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 469us/step - loss: 0.4263 - acc: 0.7983\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 426us/step - loss: 0.4258 - acc: 0.8197\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 379us/step - loss: 0.4226 - acc: 0.8256\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 371us/step - loss: 0.4247 - acc: 0.8261\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5272 - acc: 0.7932\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 438us/step - loss: 0.4470 - acc: 0.7937\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 352us/step - loss: 0.4399 - acc: 0.7937\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 4s 586us/step - loss: 0.4377 - acc: 0.7937\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 387us/step - loss: 0.4365 - acc: 0.7937\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 362us/step - loss: 0.4402 - acc: 0.7937\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 4s 510us/step - loss: 0.4350 - acc: 0.7937\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 381us/step - loss: 0.4347 - acc: 0.7937\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 369us/step - loss: 0.4328 - acc: 0.8018\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 4s 534us/step - loss: 0.4321 - acc: 0.8211\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.5046 - acc: 0.7942\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 405us/step - loss: 0.4368 - acc: 0.7944\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 4s 546us/step - loss: 0.4344 - acc: 0.7944\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 400us/step - loss: 0.4285 - acc: 0.7944\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 390us/step - loss: 0.4300 - acc: 0.7944\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 4s 593us/step - loss: 0.4294 - acc: 0.8175\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 6s 791us/step - loss: 0.4295 - acc: 0.8236\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 6s 830us/step - loss: 0.4294 - acc: 0.8228\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 484us/step - loss: 0.4288 - acc: 0.8250\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 6s 902us/step - loss: 0.4263 - acc: 0.8247\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 12s 2ms/step - loss: 0.5154 - acc: 0.7961\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 411us/step - loss: 0.4408 - acc: 0.7969\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 363us/step - loss: 0.4353 - acc: 0.7969\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 4s 598us/step - loss: 0.4368 - acc: 0.7969\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 468us/step - loss: 0.4335 - acc: 0.7969\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 468us/step - loss: 0.4288 - acc: 0.7969\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 4s 577us/step - loss: 0.4317 - acc: 0.7969\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 476us/step - loss: 0.4280 - acc: 0.8129\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 402us/step - loss: 0.4306 - acc: 0.8219\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 4s 537us/step - loss: 0.4275 - acc: 0.8242\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 11s 2ms/step - loss: 0.5106 - acc: 0.7958\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 4s 502us/step - loss: 0.4377 - acc: 0.7962\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 308us/step - loss: 0.4353 - acc: 0.7962\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 368us/step - loss: 0.4369 - acc: 0.7962\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 402us/step - loss: 0.4297 - acc: 0.7962\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 456us/step - loss: 0.4299 - acc: 0.7962\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 342us/step - loss: 0.4261 - acc: 0.7992\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 387us/step - loss: 0.4265 - acc: 0.8217\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 4s 594us/step - loss: 0.4289 - acc: 0.8232\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 4s 523us/step - loss: 0.4265 - acc: 0.8264\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 11s 2ms/step - loss: 0.5129 - acc: 0.7950\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 414us/step - loss: 0.4361 - acc: 0.7957\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 350us/step - loss: 0.4334 - acc: 0.7957\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 4s 546us/step - loss: 0.4305 - acc: 0.7957\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 385us/step - loss: 0.4280 - acc: 0.7957\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 317us/step - loss: 0.4265 - acc: 0.7975\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 355us/step - loss: 0.4255 - acc: 0.8237\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 4s 543us/step - loss: 0.4273 - acc: 0.8239\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 419us/step - loss: 0.4243 - acc: 0.8265\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 340us/step - loss: 0.4232 - acc: 0.8290\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 11s 1ms/step - loss: 0.5498 - acc: 0.7957\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 398us/step - loss: 0.4440 - acc: 0.7981\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.4309 - acc: 0.8161\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 4s 535us/step - loss: 0.4248 - acc: 0.8187\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 439us/step - loss: 0.4180 - acc: 0.8244\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 431us/step - loss: 0.4179 - acc: 0.8231\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 4s 516us/step - loss: 0.4140 - acc: 0.8231\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 4s 519us/step - loss: 0.4087 - acc: 0.8256\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 347us/step - loss: 0.4075 - acc: 0.8287\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 455us/step - loss: 0.4030 - acc: 0.8304\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4778 - acc: 0.7960\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 7s 850us/step - loss: 0.4356 - acc: 0.7960\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 7s 920us/step - loss: 0.4340 - acc: 0.7960\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 7s 821us/step - loss: 0.4351 - acc: 0.8048\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 6s 751us/step - loss: 0.4312 - acc: 0.8206\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 7s 864us/step - loss: 0.4320 - acc: 0.8213\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 7s 915us/step - loss: 0.4310 - acc: 0.8229\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 6s 751us/step - loss: 0.4257 - acc: 0.8244\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 7s 911us/step - loss: 0.4313 - acc: 0.8250\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 7s 930us/step - loss: 0.4314 - acc: 0.8251\n"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 5, 'epochs': 10, 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8306249999999998\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}