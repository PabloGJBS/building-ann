{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitf54d1120b1a246e5ae2d8e2687e569f5",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow==1.13.1 (from -r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy==1.16.2 (from -r requirements.txt (line 2))\n",
      "  Using cached https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pandas==0.24.2 (from -r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting matplotlib==3.0.3 (from -r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting Keras==2.2.4 (from -r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
      "Collecting sklearn==0.0 (from -r requirements.txt (line 6))\n",
      "Collecting six>=1.10.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/58/0aa6fb779dc69cfc811df3398fcbeaeefbf18561b6e36b185df0782781cc/absl_py-0.11.0-py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "Collecting protobuf>=3.6.1 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/fe/fd/247ef25f5ec5f9acecfbc98ca3c6aaf66716cf52509aca9a93583d410493/protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl\n",
      "Collecting wheel>=0.26 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/00/3df031b3ecd5444d572141321537080b40c1c25e1caa3d86cdd12e5e919c/wheel-0.35.1-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Collecting pytz>=2011k (from pandas==0.24.2->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.5.0 (from pandas==0.24.2->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/1b/cbd8ae738719b5f41592a12057ef5442e2ed5f5cb5451f8fc7e9f8875a1a/kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting h5py (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/70/7a/e53e500335afb6b1aade11227cdf107fca54106a1dca5c9d13242a043f3b/h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pyyaml (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "Collecting scipy>=0.14 (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting scikit-learn (from sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/ef/24a91ca96efa0d7802dffb83ccc7a3c677027bea19ec3c9ee80be740408e/Markdown-3.3.3-py3-none-any.whl\n",
      "Collecting cached-property; python_version < \"3.8\" (from h5py->Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/6d/f4bb28424bc677bce1210bc19f69a43efe823e294325606ead595211f93e/importlib_metadata-2.0.0-py2.py3-none-any.whl\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/41/ad/6a4f1a124b325618a7fb758b885b68ff7b058eec47d9220a12ab38d90b1f/zipp-3.4.0-py3-none-any.whl\n",
      "Installing collected packages: six, gast, grpcio, numpy, absl-py, mock, tensorflow-estimator, cached-property, h5py, keras-applications, astor, termcolor, protobuf, werkzeug, zipp, importlib-metadata, markdown, wheel, tensorboard, keras-preprocessing, tensorflow, pytz, python-dateutil, pandas, cycler, pyparsing, kiwisolver, matplotlib, pyyaml, scipy, Keras, joblib, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed Keras-2.2.4 absl-py-0.11.0 astor-0.8.1 cached-property-1.5.2 cycler-0.10.0 gast-0.4.0 grpcio-1.33.2 h5py-3.1.0 importlib-metadata-2.0.0 joblib-0.17.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 kiwisolver-1.3.1 markdown-3.3.3 matplotlib-3.0.3 mock-4.0.2 numpy-1.16.2 pandas-0.24.2 protobuf-3.14.0 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 pyyaml-5.3.1 scikit-learn-0.23.2 scipy-1.5.4 six-1.15.0 sklearn-0.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 threadpoolctl-2.1.0 werkzeug-1.0.1 wheel-0.35.1 zipp-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Neural Network\n",
    "\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# pip install tensorflow\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n [608 'Spain' 0 ... 0 1 112542.58]\n [502 'France' 0 ... 1 0 113931.57]\n ...\n [709 'France' 0 ... 0 1 42085.58]\n [772 'Germany' 1 ... 1 0 92888.52]\n [792 'France' 0 ... 1 0 38190.78]]\n[[1.0 0.0 0.0 ... 1 1 101348.88]\n [0.0 0.0 1.0 ... 0 1 112542.58]\n [1.0 0.0 0.0 ... 1 0 113931.57]\n ...\n [1.0 0.0 0.0 ... 0 1 42085.58]\n [0.0 1.0 0.0 ... 1 0 92888.52]\n [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding the \"Gender\" column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])\n",
    "print(X)\n",
    "# One Hot Encoding the \"Geography\" column\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8000, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/fellipe/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/fellipe/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.4841 - acc: 0.7949\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 0.4298 - acc: 0.7960\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4272 - acc: 0.7960\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4228 - acc: 0.8054\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4200 - acc: 0.8202\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4173 - acc: 0.8242\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4156 - acc: 0.8282\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4140 - acc: 0.8295\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4122 - acc: 0.8321\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.4107 - acc: 0.8330\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9947162d68>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "# classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting a single new observation\n",
    "\"\"\"Predict if the customer with the following informations will leave the bank:\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Gender: Male\n",
    "Age: 40\n",
    "Tenure: 3\n",
    "Balance: 60000\n",
    "Number of Products: 2\n",
    "Has Credit Card: Yes\n",
    "Is Active Member: Yes\n",
    "Estimated Salary: 50000\n",
    "Exited: Yes\"\"\"\n",
    "new_prediction = classifier.predict(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000, 1]])))\n",
    "new_prediction = (new_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1559   36]\n [ 285  120]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4 - Evaluating, Improving and Tuning the ANN\n",
    "\n",
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras.layers import Dropout\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 10)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.82375    0.81374999 0.83125    0.81625    0.85249999 0.81\n 0.83       0.81375    0.81874999 0.79499999]\n0.8204999953508377\n0.01453659183801273\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)\n",
    "print(mean)\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving the ANN\n",
    "# Dropout Regularization to reduce overfitting if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size': [5, 10],\n",
    "              'epochs': [5, 10],\n",
    "              'optimizer': ['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           scoring = 'accuracy',\n",
    "                           param_grid = parameters,\n",
    "                           cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0.7971\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 385us/step - loss: 0.4320 - acc: 0.7971\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 393us/step - loss: 0.4283 - acc: 0.7971\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 7s 908us/step - loss: 0.5128 - acc: 0.7964\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 403us/step - loss: 0.4431 - acc: 0.7967\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 356us/step - loss: 0.4405 - acc: 0.7967\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 358us/step - loss: 0.4374 - acc: 0.7967\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 306us/step - loss: 0.4330 - acc: 0.7967\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 408us/step - loss: 0.4362 - acc: 0.7967\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 364us/step - loss: 0.4369 - acc: 0.7967\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 350us/step - loss: 0.4313 - acc: 0.7967\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 316us/step - loss: 0.4304 - acc: 0.7967\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 307us/step - loss: 0.4376 - acc: 0.7967\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 7s 953us/step - loss: 0.4930 - acc: 0.7951\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 435us/step - loss: 0.4388 - acc: 0.7956\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 338us/step - loss: 0.4337 - acc: 0.7956\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 343us/step - loss: 0.4337 - acc: 0.7956\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 307us/step - loss: 0.4280 - acc: 0.7956\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 405us/step - loss: 0.4292 - acc: 0.8022\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 313us/step - loss: 0.4299 - acc: 0.8232\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 319us/step - loss: 0.4281 - acc: 0.8272\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 397us/step - loss: 0.4281 - acc: 0.8267\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 337us/step - loss: 0.4270 - acc: 0.8290\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 7s 956us/step - loss: 0.5014 - acc: 0.7962\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 407us/step - loss: 0.4307 - acc: 0.8072\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.4217 - acc: 0.8194\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.4130 - acc: 0.8226\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 417us/step - loss: 0.4093 - acc: 0.8224\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 321us/step - loss: 0.4094 - acc: 0.8206\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 325us/step - loss: 0.4046 - acc: 0.8226\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 313us/step - loss: 0.4058 - acc: 0.8215\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 322us/step - loss: 0.4024 - acc: 0.8217\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 314us/step - loss: 0.3992 - acc: 0.8235\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 7s 993us/step - loss: 0.4963 - acc: 0.7937\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 325us/step - loss: 0.4391 - acc: 0.7937\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 392us/step - loss: 0.4345 - acc: 0.7937\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 394us/step - loss: 0.4312 - acc: 0.7937\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 328us/step - loss: 0.4324 - acc: 0.7951\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 329us/step - loss: 0.4304 - acc: 0.8168\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 395us/step - loss: 0.4302 - acc: 0.8176\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 362us/step - loss: 0.4295 - acc: 0.8214\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 332us/step - loss: 0.4296 - acc: 0.8249\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 341us/step - loss: 0.4274 - acc: 0.8218\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 7s 986us/step - loss: 0.5015 - acc: 0.7940\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 318us/step - loss: 0.4372 - acc: 0.7944\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 338us/step - loss: 0.4339 - acc: 0.7944\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 418us/step - loss: 0.4301 - acc: 0.7944\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 301us/step - loss: 0.4294 - acc: 0.7944\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 360us/step - loss: 0.4315 - acc: 0.8022\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 460us/step - loss: 0.4280 - acc: 0.8228\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 319us/step - loss: 0.4277 - acc: 0.8237\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 337us/step - loss: 0.4277 - acc: 0.8228\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 329us/step - loss: 0.4262 - acc: 0.8269\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 7s 989us/step - loss: 0.5019 - acc: 0.7964\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 389us/step - loss: 0.4279 - acc: 0.8099\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 350us/step - loss: 0.4178 - acc: 0.8183\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 375us/step - loss: 0.4182 - acc: 0.8212\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 412us/step - loss: 0.4071 - acc: 0.8207\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 426us/step - loss: 0.4081 - acc: 0.8229\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 328us/step - loss: 0.4070 - acc: 0.8240\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 403us/step - loss: 0.4077 - acc: 0.8168\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 4s 486us/step - loss: 0.4054 - acc: 0.8196\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 362us/step - loss: 0.4049 - acc: 0.8182\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.5161 - acc: 0.7954\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 327us/step - loss: 0.4433 - acc: 0.7962\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 364us/step - loss: 0.4413 - acc: 0.7962\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 375us/step - loss: 0.4343 - acc: 0.7962\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 372us/step - loss: 0.4336 - acc: 0.7962\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 316us/step - loss: 0.4348 - acc: 0.7962\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 4s 523us/step - loss: 0.4322 - acc: 0.7962\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 249us/step - loss: 0.4309 - acc: 0.7962\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 405us/step - loss: 0.4299 - acc: 0.7962\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 341us/step - loss: 0.4304 - acc: 0.7962\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5079 - acc: 0.7951\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 364us/step - loss: 0.4389 - acc: 0.7957\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 354us/step - loss: 0.4328 - acc: 0.7956\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 343us/step - loss: 0.4271 - acc: 0.8078\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 349us/step - loss: 0.4242 - acc: 0.8225\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 363us/step - loss: 0.4183 - acc: 0.8261\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 349us/step - loss: 0.4179 - acc: 0.8285\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 360us/step - loss: 0.4166 - acc: 0.8271\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 361us/step - loss: 0.4179 - acc: 0.8267\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 364us/step - loss: 0.4176 - acc: 0.8235\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.4953 - acc: 0.7956\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 361us/step - loss: 0.4379 - acc: 0.7961\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 361us/step - loss: 0.4357 - acc: 0.7961\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 366us/step - loss: 0.4322 - acc: 0.7961\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 358us/step - loss: 0.4313 - acc: 0.7961\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 339us/step - loss: 0.4289 - acc: 0.8022\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 352us/step - loss: 0.4275 - acc: 0.8193\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 368us/step - loss: 0.4304 - acc: 0.8208\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 356us/step - loss: 0.4271 - acc: 0.8231\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 360us/step - loss: 0.4253 - acc: 0.8228\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5008 - acc: 0.7965\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 379us/step - loss: 0.4398 - acc: 0.7971\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 353us/step - loss: 0.4333 - acc: 0.7971\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 359us/step - loss: 0.4318 - acc: 0.7971\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 363us/step - loss: 0.4278 - acc: 0.7971\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 363us/step - loss: 0.4283 - acc: 0.8136\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 351us/step - loss: 0.4255 - acc: 0.8253\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 339us/step - loss: 0.4260 - acc: 0.8262\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 331us/step - loss: 0.4235 - acc: 0.8286\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 347us/step - loss: 0.4229 - acc: 0.8269\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.4993 - acc: 0.7967\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 363us/step - loss: 0.4362 - acc: 0.7967\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 353us/step - loss: 0.4348 - acc: 0.7967\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.4314 - acc: 0.7967\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 356us/step - loss: 0.4298 - acc: 0.7967\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 354us/step - loss: 0.4268 - acc: 0.8069\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 340us/step - loss: 0.4260 - acc: 0.8249\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 363us/step - loss: 0.4243 - acc: 0.8258\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 358us/step - loss: 0.4250 - acc: 0.8265\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 346us/step - loss: 0.4250 - acc: 0.8285\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5101 - acc: 0.7947\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.4423 - acc: 0.7956\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 358us/step - loss: 0.4332 - acc: 0.7956\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 353us/step - loss: 0.4314 - acc: 0.7956\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 348us/step - loss: 0.4318 - acc: 0.7956\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 406us/step - loss: 0.4294 - acc: 0.7956\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 419us/step - loss: 0.4272 - acc: 0.8075\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 391us/step - loss: 0.4300 - acc: 0.8214\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 360us/step - loss: 0.4273 - acc: 0.8228\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 364us/step - loss: 0.4249 - acc: 0.8262\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5055 - acc: 0.7975\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 323us/step - loss: 0.4382 - acc: 0.7975\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 362us/step - loss: 0.4349 - acc: 0.7975\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 387us/step - loss: 0.4316 - acc: 0.7975\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 428us/step - loss: 0.4305 - acc: 0.7975\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 353us/step - loss: 0.4239 - acc: 0.7975\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 363us/step - loss: 0.4265 - acc: 0.8089\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 385us/step - loss: 0.4257 - acc: 0.8233\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 411us/step - loss: 0.4263 - acc: 0.8233\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 363us/step - loss: 0.4256 - acc: 0.8254\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5206 - acc: 0.7933\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 456us/step - loss: 0.4449 - acc: 0.7937\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.4382 - acc: 0.7937\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 451us/step - loss: 0.4373 - acc: 0.7937\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 430us/step - loss: 0.4337 - acc: 0.7937\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 190us/step - loss: 0.4340 - acc: 0.7937\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 325us/step - loss: 0.4351 - acc: 0.8010\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 402us/step - loss: 0.4352 - acc: 0.8199\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 300us/step - loss: 0.4302 - acc: 0.8224\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 254us/step - loss: 0.4320 - acc: 0.8218\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5141 - acc: 0.7944\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 256us/step - loss: 0.4394 - acc: 0.7944\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 216us/step - loss: 0.4374 - acc: 0.7944\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 342us/step - loss: 0.4391 - acc: 0.7944\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 307us/step - loss: 0.4366 - acc: 0.7944\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 364us/step - loss: 0.4342 - acc: 0.7944\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 366us/step - loss: 0.4350 - acc: 0.7944\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 390us/step - loss: 0.4293 - acc: 0.7944\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 403us/step - loss: 0.4306 - acc: 0.8019\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 379us/step - loss: 0.4323 - acc: 0.8192\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5155 - acc: 0.7968\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 412us/step - loss: 0.4424 - acc: 0.7969\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 384us/step - loss: 0.4358 - acc: 0.7969\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 387us/step - loss: 0.4349 - acc: 0.7969\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.4323 - acc: 0.7969\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 380us/step - loss: 0.4341 - acc: 0.7969\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 389us/step - loss: 0.4317 - acc: 0.7969\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 397us/step - loss: 0.4274 - acc: 0.7993\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 413us/step - loss: 0.4284 - acc: 0.8217\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 398us/step - loss: 0.4314 - acc: 0.8261\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5220 - acc: 0.7954\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 333us/step - loss: 0.4394 - acc: 0.7962\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 336us/step - loss: 0.4294 - acc: 0.7962\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 380us/step - loss: 0.4311 - acc: 0.7962\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.4301 - acc: 0.7962\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 345us/step - loss: 0.4340 - acc: 0.7962\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 339us/step - loss: 0.4278 - acc: 0.8082\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 445us/step - loss: 0.4252 - acc: 0.8235\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 406us/step - loss: 0.4247 - acc: 0.8268\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 386us/step - loss: 0.4271 - acc: 0.8292\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5149 - acc: 0.7957\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 337us/step - loss: 0.4391 - acc: 0.7957\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 387us/step - loss: 0.4354 - acc: 0.7957\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 411us/step - loss: 0.4338 - acc: 0.7957\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 360us/step - loss: 0.4341 - acc: 0.7957\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 350us/step - loss: 0.4309 - acc: 0.7957\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 380us/step - loss: 0.4307 - acc: 0.7957\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 453us/step - loss: 0.4302 - acc: 0.7997\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 426us/step - loss: 0.4285 - acc: 0.8201\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 397us/step - loss: 0.4283 - acc: 0.8228\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5194 - acc: 0.7950\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 385us/step - loss: 0.4420 - acc: 0.7961\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 387us/step - loss: 0.4391 - acc: 0.7961\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.4355 - acc: 0.7961\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 397us/step - loss: 0.4354 - acc: 0.7961\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 390us/step - loss: 0.4335 - acc: 0.7961\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 368us/step - loss: 0.4308 - acc: 0.7961\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.4287 - acc: 0.7987\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 390us/step - loss: 0.4319 - acc: 0.8204\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.4305 - acc: 0.8231\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.4852 - acc: 0.7956\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 6s 757us/step - loss: 0.4400 - acc: 0.7960\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 6s 749us/step - loss: 0.4324 - acc: 0.7960\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 5s 680us/step - loss: 0.4307 - acc: 0.7989\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 6s 761us/step - loss: 0.4301 - acc: 0.8219\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 6s 764us/step - loss: 0.4309 - acc: 0.8235\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 6s 742us/step - loss: 0.4329 - acc: 0.8249\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 6s 729us/step - loss: 0.4326 - acc: 0.8270\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 6s 762us/step - loss: 0.4337 - acc: 0.8253\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 6s 739us/step - loss: 0.4310 - acc: 0.8263\n"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 5, 'epochs': 10, 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.834875\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}