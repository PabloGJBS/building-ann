{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitf54d1120b1a246e5ae2d8e2687e569f5",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow==1.13.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 92.5MB 13kB/s \n",
      "\u001b[?25hCollecting numpy==1.16.2 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.3MB 100kB/s \n",
      "\u001b[?25hCollecting pandas==0.24.2 (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.1MB 162kB/s \n",
      "\u001b[?25hCollecting matplotlib==3.0.3 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl (13.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.0MB 98kB/s \n",
      "\u001b[?25hCollecting Keras==2.2.4 (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 2.5MB/s \n",
      "\u001b[?25hCollecting sklearn==0.0 (from -r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 2.1MB/s \n",
      "\u001b[?25hCollecting six>=1.10.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/30/79/510974552cebff2ba04038544799450defe75e96ea5f1675dbf72cc8744f/protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 1.1MB/s \n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 495kB/s \n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/1e/5d65ae830536fdb67f10f4bcedca6eb59190ad60d20d796ef3ccdfda4797/grpcio-1.33.2.tar.gz (20.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.9MB 53kB/s \n",
      "\u001b[?25hCollecting absl-py>=0.1.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/58/0aa6fb779dc69cfc811df3398fcbeaeefbf18561b6e36b185df0782781cc/absl_py-0.11.0-py3-none-any.whl (127kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 2.7MB/s \n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 6.9MB/s \n",
      "\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.9MB/s \n",
      "\u001b[?25hCollecting gast>=0.2.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Collecting wheel>=0.26 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/00/3df031b3ecd5444d572141321537080b40c1c25e1caa3d86cdd12e5e919c/wheel-0.35.1-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.5.0 (from pandas==0.24.2->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting pytz>=2011k (from pandas==0.24.2->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 2.7MB/s \n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/1b/cbd8ae738719b5f41592a12057ef5442e2ed5f5cb5451f8fc7e9f8875a1a/kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 1.2MB/s \n",
      "\u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pyyaml (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "Collecting scipy>=0.14 (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.9MB 56kB/s \n",
      "\u001b[?25hCollecting h5py (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/70/7a/e53e500335afb6b1aade11227cdf107fca54106a1dca5c9d13242a043f3b/h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.0MB 437kB/s \n",
      "\u001b[?25hCollecting scikit-learn (from sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.8MB 263kB/s \n",
      "\u001b[?25hCollecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
      "Collecting setuptools (from protobuf>=3.6.1->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/38/c21ef5034684ffc0412deefbb07d66678332290c14bb5269c85145fbd55e/setuptools-50.3.2-py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/ef/24a91ca96efa0d7802dffb83ccc7a3c677027bea19ec3c9ee80be740408e/Markdown-3.3.3-py3-none-any.whl (96kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 1.3MB/s \n",
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 2.2MB/s \n",
      "\u001b[?25hCollecting cached-property; python_version < \"3.8\" (from h5py->Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/6d/f4bb28424bc677bce1210bc19f69a43efe823e294325606ead595211f93e/importlib_metadata-2.0.0-py2.py3-none-any.whl\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/41/ad/6a4f1a124b325618a7fb758b885b68ff7b058eec47d9220a12ab38d90b1f/zipp-3.4.0-py3-none-any.whl\n",
      "Building wheels for collected packages: sklearn, termcolor, grpcio\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/fellipe/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/fellipe/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for grpcio ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/fellipe/.cache/pip/wheels/b4/7b/76/9fa06c695bb5ce8dcc440b1904e5b0554ab183c46ca4ea2e86\n",
      "Successfully built sklearn termcolor grpcio\n",
      "Installing collected packages: numpy, mock, six, absl-py, tensorflow-estimator, setuptools, protobuf, termcolor, grpcio, zipp, importlib-metadata, markdown, werkzeug, wheel, tensorboard, astor, keras-preprocessing, cached-property, h5py, keras-applications, gast, tensorflow, python-dateutil, pytz, pandas, kiwisolver, pyparsing, cycler, matplotlib, pyyaml, scipy, Keras, threadpoolctl, joblib, scikit-learn, sklearn\n",
      "Successfully installed Keras-2.2.4 absl-py-0.11.0 astor-0.8.1 cached-property-1.5.2 cycler-0.10.0 gast-0.4.0 grpcio-1.33.2 h5py-3.1.0 importlib-metadata-2.0.0 joblib-0.17.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 kiwisolver-1.3.1 markdown-3.3.3 matplotlib-3.0.3 mock-4.0.2 numpy-1.16.2 pandas-0.24.2 protobuf-3.13.0 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 pyyaml-5.3.1 scikit-learn-0.23.2 scipy-1.5.4 setuptools-50.3.2 six-1.15.0 sklearn-0.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 threadpoolctl-2.1.0 werkzeug-1.0.1 wheel-0.35.1 zipp-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Neural Network\n",
    "\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# pip install tensorflow\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras\n",
    "\n",
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n [608 'Spain' 0 ... 0 1 112542.58]\n [502 'France' 0 ... 1 0 113931.57]\n ...\n [709 'France' 0 ... 0 1 42085.58]\n [772 'Germany' 1 ... 1 0 92888.52]\n [792 'France' 0 ... 1 0 38190.78]]\n[[1.0 0.0 0.0 ... 1 1 101348.88]\n [0.0 0.0 1.0 ... 0 1 112542.58]\n [1.0 0.0 0.0 ... 1 0 113931.57]\n ...\n [1.0 0.0 0.0 ... 0 1 42085.58]\n [0.0 1.0 0.0 ... 1 0 92888.52]\n [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding the \"Gender\" column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])\n",
    "print(X)\n",
    "# One Hot Encoding the \"Geography\" column\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8000, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/fellipe/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.5143 - acc: 0.8009\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.4186 - acc: 0.8070\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3991 - acc: 0.8157\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3861 - acc: 0.8262\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3762 - acc: 0.8370\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3708 - acc: 0.8414\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3670 - acc: 0.8441\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3652 - acc: 0.8424\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3636 - acc: 0.8426\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3612 - acc: 0.8444\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3592 - acc: 0.8485\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3577 - acc: 0.8487\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3552 - acc: 0.8481\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3539 - acc: 0.8531\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3526 - acc: 0.8507\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3510 - acc: 0.8516\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3516 - acc: 0.8516\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3509 - acc: 0.8529\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3505 - acc: 0.8511\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3502 - acc: 0.8521\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3493 - acc: 0.8531\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3540 - acc: 0.8537\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3523 - acc: 0.8537\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3501 - acc: 0.8517\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3524 - acc: 0.8511\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3506 - acc: 0.8550\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3503 - acc: 0.8537\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3496 - acc: 0.8522\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3480 - acc: 0.8559\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3480 - acc: 0.8545\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3476 - acc: 0.8552\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3476 - acc: 0.8539\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3470 - acc: 0.8549\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3472 - acc: 0.8539\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3497 - acc: 0.8552\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3470 - acc: 0.8540\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3469 - acc: 0.8536\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3467 - acc: 0.8541\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3470 - acc: 0.8537\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3460 - acc: 0.8520\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3463 - acc: 0.8535\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3489 - acc: 0.8522\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3465 - acc: 0.8552\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3477 - acc: 0.8524\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3459 - acc: 0.8561\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3465 - acc: 0.8525\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3468 - acc: 0.8531\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3462 - acc: 0.8542\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3462 - acc: 0.8556\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3464 - acc: 0.8527\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3460 - acc: 0.8545\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3458 - acc: 0.8552\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3465 - acc: 0.8526\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3454 - acc: 0.8540\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3474 - acc: 0.8525\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3454 - acc: 0.8536\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 0.3450 - acc: 0.8550\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 0.3511 - acc: 0.8514\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3488 - acc: 0.8555\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3461 - acc: 0.8545\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3458 - acc: 0.8539\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3455 - acc: 0.8544\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3455 - acc: 0.8551\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 0.3455 - acc: 0.8536\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 0.3454 - acc: 0.8535\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.3458 - acc: 0.8550\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3517 - acc: 0.8539\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3467 - acc: 0.8551\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3447 - acc: 0.8561\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3474 - acc: 0.8555\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3452 - acc: 0.8547\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3453 - acc: 0.8551\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3458 - acc: 0.8536\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3454 - acc: 0.8547\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3457 - acc: 0.8554\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3451 - acc: 0.8522\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3467 - acc: 0.8547\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3454 - acc: 0.8562\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3492 - acc: 0.8560\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3458 - acc: 0.8541\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3452 - acc: 0.8566\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3455 - acc: 0.8564\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3452 - acc: 0.8542\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3463 - acc: 0.8545\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3484 - acc: 0.8552\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3453 - acc: 0.8545\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3449 - acc: 0.8544\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3448 - acc: 0.8539\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3455 - acc: 0.8555\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3461 - acc: 0.8540\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.3455 - acc: 0.8556\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 0.3447 - acc: 0.8556\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.3466 - acc: 0.8537\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.3452 - acc: 0.8555\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.3445 - acc: 0.8547\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.3453 - acc: 0.8542\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3448 - acc: 0.8550\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3457 - acc: 0.8550\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 154us/step - loss: 0.3444 - acc: 0.8551\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 0.3474 - acc: 0.8540\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ae612ff28>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1518   77]\n [ 198  207]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}