{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit5aff65cb5d064dc4bf8e53621272c904",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow==1.13.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 92.5MB 19kB/s \n",
      "\u001b[?25hCollecting numpy==1.16.2 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.3MB 99kB/s \n",
      "\u001b[?25hCollecting pandas==0.24.2 (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.1MB 167kB/s \n",
      "\u001b[?25hCollecting matplotlib==3.0.3 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl (13.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.0MB 130kB/s \n",
      "\u001b[?25hCollecting Keras==2.2.4 (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 1.1MB/s \n",
      "\u001b[?25hCollecting sklearn==0.0 (from -r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/58/0aa6fb779dc69cfc811df3398fcbeaeefbf18561b6e36b185df0782781cc/absl_py-0.11.0-py3-none-any.whl (127kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 1.7MB/s \n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 2.0MB/s \n",
      "\u001b[?25hCollecting wheel>=0.26 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/00/3df031b3ecd5444d572141321537080b40c1c25e1caa3d86cdd12e5e919c/wheel-0.35.1-py2.py3-none-any.whl\n",
      "Collecting six>=1.10.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 437kB/s \n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 2.6MB/s \n",
      "\u001b[?25hCollecting protobuf>=3.6.1 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/30/79/510974552cebff2ba04038544799450defe75e96ea5f1675dbf72cc8744f/protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 767kB/s \n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/1e/5d65ae830536fdb67f10f4bcedca6eb59190ad60d20d796ef3ccdfda4797/grpcio-1.33.2.tar.gz (20.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.9MB 78kB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 1.2MB/s \n",
      "\u001b[?25hCollecting python-dateutil>=2.5.0 (from pandas==0.24.2->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting pytz>=2011k (from pandas==0.24.2->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 1.3MB/s \n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/1b/cbd8ae738719b5f41592a12057ef5442e2ed5f5cb5451f8fc7e9f8875a1a/kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 856kB/s \n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Collecting pyyaml (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K    100% |████████████████████████████████| 276kB 1.6MB/s \n",
      "\u001b[?25hCollecting scipy>=0.14 (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.9MB 66kB/s \n",
      "\u001b[?25hCollecting h5py (from Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/70/7a/e53e500335afb6b1aade11227cdf107fca54106a1dca5c9d13242a043f3b/h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.0MB 377kB/s \n",
      "\u001b[?25hCollecting scikit-learn (from sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.8MB 208kB/s \n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/ef/24a91ca96efa0d7802dffb83ccc7a3c677027bea19ec3c9ee80be740408e/Markdown-3.3.3-py3-none-any.whl (96kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 1.5MB/s \n",
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 1.2MB/s \n",
      "\u001b[?25hCollecting setuptools (from protobuf>=3.6.1->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/38/c21ef5034684ffc0412deefbb07d66678332290c14bb5269c85145fbd55e/setuptools-50.3.2-py3-none-any.whl\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
      "Collecting cached-property; python_version < \"3.8\" (from h5py->Keras==2.2.4->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 1.3MB/s \n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/6d/f4bb28424bc677bce1210bc19f69a43efe823e294325606ead595211f93e/importlib_metadata-2.0.0-py2.py3-none-any.whl\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/41/ad/6a4f1a124b325618a7fb758b885b68ff7b058eec47d9220a12ab38d90b1f/zipp-3.4.0-py3-none-any.whl\n",
      "Building wheels for collected packages: sklearn, termcolor, grpcio, pyyaml\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/paulo/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/paulo/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for grpcio ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/paulo/.cache/pip/wheels/b4/7b/76/9fa06c695bb5ce8dcc440b1904e5b0554ab183c46ca4ea2e86\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/paulo/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built sklearn termcolor grpcio pyyaml\n",
      "Installing collected packages: gast, six, absl-py, termcolor, numpy, cached-property, h5py, keras-applications, wheel, setuptools, protobuf, zipp, importlib-metadata, markdown, grpcio, werkzeug, tensorboard, astor, keras-preprocessing, mock, tensorflow-estimator, tensorflow, python-dateutil, pytz, pandas, kiwisolver, cycler, pyparsing, matplotlib, pyyaml, scipy, Keras, joblib, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed Keras-2.2.4 absl-py-0.11.0 astor-0.8.1 cached-property-1.5.2 cycler-0.10.0 gast-0.4.0 grpcio-1.33.2 h5py-3.1.0 importlib-metadata-2.0.0 joblib-0.17.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 kiwisolver-1.3.1 markdown-3.3.3 matplotlib-3.0.3 mock-4.0.2 numpy-1.16.2 pandas-0.24.2 protobuf-3.13.0 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 pyyaml-5.3.1 scikit-learn-0.23.2 scipy-1.5.4 setuptools-50.3.2 six-1.15.0 sklearn-0.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 threadpoolctl-2.1.0 werkzeug-1.0.1 wheel-0.35.1 zipp-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Artificial Neural Network\n",
    "\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# pip install tensorflow\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras\n",
    "\n",
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n [0.0 0.0 1.0 ... 0 1 112542.58]\n [1.0 0.0 0.0 ... 1 0 113931.57]\n ...\n [1.0 0.0 0.0 ... 0 1 42085.58]\n [0.0 1.0 0.0 ... 1 0 92888.52]\n [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/paulo/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "8000/8000 [==============================] - 2s 199us/step - loss: 0.4794 - acc: 0.7960\n",
      "Epoch 2/30\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.4229 - acc: 0.7960\n",
      "Epoch 3/30\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.4163 - acc: 0.7947\n",
      "Epoch 4/30\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.4084 - acc: 0.8041\n",
      "Epoch 5/30\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3979 - acc: 0.8114\n",
      "Epoch 6/30\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3957 - acc: 0.8214\n",
      "Epoch 7/30\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.4027 - acc: 0.8351\n",
      "Epoch 8/30\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.4017 - acc: 0.8387\n",
      "Epoch 9/30\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3844 - acc: 0.8364\n",
      "Epoch 10/30\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3792 - acc: 0.8390\n",
      "Epoch 11/30\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3814 - acc: 0.8425\n",
      "Epoch 12/30\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3762 - acc: 0.8446\n",
      "Epoch 13/30\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3752 - acc: 0.8442\n",
      "Epoch 14/30\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3728 - acc: 0.8445\n",
      "Epoch 15/30\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3730 - acc: 0.8447\n",
      "Epoch 16/30\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3687 - acc: 0.8459\n",
      "Epoch 17/30\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3729 - acc: 0.8466\n",
      "Epoch 18/30\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3736 - acc: 0.8456\n",
      "Epoch 19/30\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3673 - acc: 0.8487\n",
      "Epoch 20/30\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3669 - acc: 0.8475\n",
      "Epoch 21/30\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3661 - acc: 0.8484\n",
      "Epoch 22/30\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3636 - acc: 0.8477\n",
      "Epoch 23/30\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3637 - acc: 0.8496\n",
      "Epoch 24/30\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3672 - acc: 0.8482\n",
      "Epoch 25/30\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3659 - acc: 0.8481\n",
      "Epoch 26/30\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3642 - acc: 0.8496\n",
      "Epoch 27/30\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3638 - acc: 0.8497\n",
      "Epoch 28/30\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3593 - acc: 0.8531\n",
      "Epoch 29/30\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3621 - acc: 0.8525\n",
      "Epoch 30/30\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3679 - acc: 0.8539\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f880b360e48>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1520   75]\n [ 211  194]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}